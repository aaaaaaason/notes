* Objects are structures allocated on the heap. Special rules apply to the use of objects to ensure
  they are properly garbage-collected. Objects are never allocated statically or on the stack. but Type
  objects are exceptions to it, standard types are represented by statically initialized type objects.

* Once allocated an object keeps the same size and address. Not all objects of the same type have the same
  size. And nothing is actually declared as a PyObject, but every pointer to a python object can be cast
  to a PyObject*. This is inheritance build by hand.

* typedef struct _object {
    struct _object *_ob_next;
    struct _object *_ob_prev;
    Py_ssize_t ob_ref_cnt;
    struct _typeobject *ob_type;
} PyObject;

* struct _typeobject is also in object.h, this is the main structure of an object:
    - tp_name is for printing, in format "<module>.<name>"
    - tp_basicsize, tp_itemsize are for allocation
    - typedef void (*destructor)(PyObject *) tp_dealloc, 
      typedef int (*printfunc)(PyObject *, FILE *, int) tp_print, ... name with postfix func are fp
    - PyAsyncMethods has three fps called am_await, am_aiter, am_anext  
    - PyNumberMethods for all number related operations
    - PySequenceMethods for len, concat, repeat, slice, ...
    - PyMappingMethods has mp_length, mp_subscript, mp_ass_subscript
    - hash, call, str, getattr, set attr, init, new, ...

* Python has another object type, based on PyObject, to represent like variable-sized objects:

* typedef struct {
    PyObject ob_base;
    Py_ssize_t ob_size; /* Number of items in variable part */
} PyVarObject

* Let's see the long integer object inteface:

* typedef struct _longobject PyLongObject;
  struct _longobject {
     PyVarObject ob_base;
     digit ob_digit[1]; /* digit is uint32 */
  }

* And for PyLongObject, its PyTypeObject(struct _typeobject) points to PyLong_Type, we can see that
  its tp_name is 'int', tp_basicsize is offsetof(PyLongObject, ob_digit), tp_itemsize = sizeof(digit),
  besides, it this type implement some operations, the callback will be there ...

* Regarding to the number operation, we can check long_as_number (pointed by tp_as_number), it is an
  array of type PyNumberMethods and it has function pointers such as nb_add, nb_multiply, ...

* PyLongType (and others) has an var object pointing to PyType_Type and it has an var object pointing to
  itself

* When the object's refcnt = 0, it will call tp_dealloc fp, but type object won't be dealloc

* for long type, python keeps NSMALLPOSINT and NSMALLNEGINT and in this range we preallocate an array for
  optimization. When long object is allocated, the size is offsetof(PyLongObject, ob_digit) + 
  sizeof(digit) * size
  
* For methods of each types, we can check the static array of type PyMethodDef:
    - struct PyMethodDef {
        const char *ml_name; /* the name of the built-in function/method */
        PyCFunction ml_meth; /* the C function that implements it */
        int ml_flag;         /* mostly describes the args needs for this C function */
        const char *ml_doc;  /* The __doc__ attribute, or NULL */
    }
  
* PyUnicode_Type is the 'str' type, and the new object was allocated in PyUnicode_New, it checks whether
  the char_size is 1, 2 or 4 (is_sharing = 1, in 2 or 4 cases) then object = PyObject_MALLOC(struct_size +
  (size + 1) * char_size). struct_size = sizeof(PyCompactUnicodeObject), or sizeof(PyASCIIObject).
  PyASCIIObject is used only when char_size = 1. 

* If checking unicodeobject.h, we'll see actually there're 4 forms of Unicode string:
    - PyASCIIObject (compact ascii)
    - PyCompactUnicodeObject (compact)
    - PyUnicodeObject (legacy string, not ready)
    - PyUnicodeObject (legacy string, ready)
    - compact strings use only one memory block, legacy string use 1 memory block and 1 char block 
    - legacy strings are created by PyUnicode_FromUnicode and PyUnicode_FromStringAndSize
    - we can check the site http://legacy.python.org/dev/peps/pep-0393/ and it said the recommended
      way to create a Unicode object is to use Py_Unicode_New now

* PyCompactUnicodeObject has a PyASCIIObject inside

* typedef struct {
    PyVarObject ob_base;
    PyObject *ob_item[1];
  } PyTupleObject;

* Tuple objects use _PyObject_VAR_SIZE (returns typeobj->tp_basicsize + typeobj->itemsize * nitems) to
  allocate its memory (this marco should also be used by other variable sized object). This is called by
  Py_Tuple_New and when it returns, we can assign object iteratively to ob_item[i]

* Tuple objects (and list objects ...maybe more) have static freelist array pointing to objects to save
  the times for malloc.
  
* typedef struct {
    PyVarObject ob_base;   /* ob_size means the actual elements inside */
    PyObject **ob_item;    /* it points to a space for allocated elements*/
    Py_ssize_t allocated;  /* this is to describe the size of allocated space */
  } PyListObject;
    - this struct design means that when the elements increase, we can reallocate a bigger space

* typedef struct {
    PyObject ob_base;        /* not variable type, why? not important? */
    Py_ssize_t ma_used;
    uint64_t ma_version_tag; /* dictionary version, globally unique, value changes each modified */
    PyDictKeysObject *ma_keys;
    PyObject **ma_values;    /* if NULL, pairs are in ma_keys (combined), otherwise stored separately */
  } PyDictObject

* struct _dictkeysobject {
    Py_ssize_t dk_refcnt;
    Py_ssize_t dk_size;          /* size of the hash table, must be power of 2 */
    dict_lookup_func dk_lookup;  /* lookdict(), lookdict_unicode(), lookdict_unicode_nodummy, lookdict_split */
    Py_ssize_t dk_usable;        /* number of usable entries in dk_entries */
    Py_ssize_t dk_nentries;      /* number of used entries in dk_entries */
    union {
        int8_t as_1[8];
        int16_t as_2[4];
        int32_t as_4[2];
        int64_t as_8[1]'
    } dk_indices;
  }
    - dk_indices is the head of array of indices and dk_enties follows. See details as the top of dictobject.c
    - dk_indices is the actual hash table, it holds index in entries array or DKIX_EMPTY(-1), DKIX_DUMMY(-2)
    - Because dk_indices entry can hold negative numbers, for dk_size <= 127, we can use 'as_1'; for 
      dk_size <= 2**15, we can use 'as_2'  
 
* typedef struct {
    Py_hash_t me_hash; /* cached hashed code of me_key*/
    PyObject *me_key;
    PyObject *me_value; 
  } 

* PyDict_GetItem(PyObject *op, PyObject *key)
    - when key is not PyUnicode_Type, or ((PyASCIIObject *) key)->hash == -1, we use PyObject_Hash(key) as
      hash
    - then we have ix = (mp->ma_keys->dk_lookup)(mp, key, hash, &value)

* In PyDict_SetItem, it calls insertdict(mp, key, hash, value) and we may call insertion_resize then
  dictresize to restructure the table by allocating a new table and reinserting all items again   

* typedef struct {
    PyObject ob_base;
    int co_argcount;         /* arguments, except *arg */
    int co_kwonlyargcount;   /* keyword only argument, like c in def foo(a, b, *, c):, then we have to use
                                foo('a', 'b', c='c'), check PEP3102, they're arguments that can only be supplied by 
                                keyword and which will never be automatically filled in by a positional argument */
    int co_nlocals;          /* local variables */
    int co_stacksize;        /* entries needed for evaluation stack */
    int co_flags;            /* use dis.COMPILER_FLAG_NAME, 1: OPTIMIZED, 2:NEWLOCALS, 4:VARARGS, 8:VARKEYWORDS, 16:NESTED, 32:GENERATOR, ...*/
    int co_firstlineno;      /* first source line number */
    PyObject *co_code;       /* instruction op code, bytes type */
    PyObject *co_const;      /* tuple for constants, any code object inside current code object will be listed here!!! */
    PyObject *co_names;      /* tuple of strings, like symbol table */
    PyObject *co_varnames;   /* tuple of strings of local variable names */
    PyObject *co_freevars;   /* tuple of strings of free variable names, free variable is a variable from an outer function */
    PyObject *co_cellvars;   /* tuple of strings of cell variable names, cell variable is a variable used by inner function */
    /* The rest aren't used in either hash or comparisons, except for co_name used in both */
    Py_ssize_t *co_cell2arg; /* Map cellvars which are arguments, a pointer to an array and each entry stores the index in total arguments */
    PyObject *co_filename;   /* unicode (where it was loaded from) */
    PyObject *co_name;       /* unicode, the name of the code block */
    PyObject *co_lnotab;     /* pairs of (pyc code, source code) in byte string, afterward pair is coded with difference to the previous one */
    ...  
  } PyCodeObject;
    - PyCodeObject is the whole code object, there's no other field with it for memory allocation (PyCode_New)
    - it has code_memberlist which registers most of its methods like co_argcount, co_keyonlyargcount, ...

* typedef struct PyMemerDef {
    const char *name; /* name of the method */
    int type;         /* return type of the method */
    Py_ssize_t;       /* the wanted value's byte offset in code object */
    int flag;         /* READONLY in code object */
    const char *doc;  /* not used in code object */
  } PyMemberDef

* frame object can be got in python by calling sys._getframe()

* typedef struct _frame {
    PyVarObject ob_base;
    struct _frame *f_back;  /* previous from, or NULL */
    PyCodeObject *f_code;   /* code segment */
    PyObject *f_builtins;   /* builtin symbol table, PyDictObject */
    PyObject *f_globals;    /* global symbol table, PyDictObject */
    PyObject *f_locals;     /* local symbol table, PyDictObject */
    PyObject **f_valuestack; /* point after the last local, stack with highest address */
    PyObject **f_stacktop;   /* next free slot in f_valuestack, frame creation sets to f_valuestack */
    PyObject *f_trace;     /* trace function, is a function called at the start of each source code line, for debugger */
    char f_trace_lines;    /* emit per-line trace events? */
    char f_trace_opcodes;  /* emit per-line trace opcode? */
    PyObject f_gen;        /* borrowed reference to a generator, or NULL, for running generator code */
    int lasti;             /* last instruction if called, index into the bytecode string of the code object */
    int f_lineno;          /* current line number but only valid when f_trace is valid, so call PyFrame_GetLineNumber() */
    int f_iblock;          /* index_in_f_blockstack */
    char f_executing;      /* whether the frame is still executing */
    PyTryBlock f_blockstack[CO_MAXBLOCKS]; /* for try and loop blocks */
    PyObject f_localsplus[1]; /* locals + stack, dynamically sized */ 
  } PyFrameObject;

* typedef struct {
    int b_type;      /* what kind of block this is */
    int b_handler;   /* where to jump to find handler */
    int b_level;     /* value stack level to pop to */
  } PyTryBlock;

* PyFrame_New calls _PyFrame_New_NoTrack(PyThreadState *tstate, PyCodeObject *code, PyObject *globals, PyObject *local)
    - the allocate size is ncells (PyTuple_GET_SIZE(code->cellvars)) + nfrees (PyTuple_GET_SIZE(code->co_freevars)), 
      then set f->code = code, set f_valuestack = f_localsplus + ncells + nfrees + code->co_nlocals, ...
    - set f->lasti = -1, f_lineno = code->co_firstlineno, f->globals = globals
    - if back == NULL || back->globals != globals, we check if globals has builtin module and use its dict for f->builtins
      otherwise we create a new dict
    - if code->co_flags has CO_NEWLOCALS, we set f->locals a new dict, otherwise we set f->locals = globals   

* typedef struct {
    PyObject_HEAD;           
    PyObject *md_dict;           /* __dict__ of this module */ 
    struct PyModuleDef *md_def;  /* initialized and set in _PyModule_CreateInitialized, */
    void *md_state;              /* points to a memory space with size = md_def->m_size, each module has its usage */
    PyObject *md_weaklist;
    PyObject *md_name;           /* module name */
  } PyModuleObject;
  - PyModule_New calls PyModule_NewObject(nameobj) and it creates a PyModuleObject based on PyModule_Type, then
    it sets md_def, md_state, md_weaklist, md_name as NULL, but call module_init_dict for md_dict
  - module_init_dict pushes __name__, __doc__, __package__, __loader__, __spec__ into md_dict but only __name__
    has a value, others are NULL    

* webpage regarding to sys module, https://docs.python.org/3.0/library/sys.html

* typedef struct {
    PyModuleDefBase m_base; /* always initialize this member to PyModuleDef_HEAD_INIT */
    const_char *m_name;     /* name for the new module */
    const_char *m_doc;      /* docstring for the module */
    Py_ssize_t m_size;      /* module state may be kept in a per-module memory area that can be retrieved
                               with PyModule_Getstate(), rather than in static globals. This makes modules
                               safe for use in multiple sub-interpreters. This memory is allocated based on it */
    PyMethodDef *m_methods; /* a pointer to a table of module-level functions, it can be NULL */
    struct PyModuleDef_Slot *m_slots; /* an array of slot definitions for multi-phase initialization */
    traverseproc m_traverse;  /* a traversal function to call during GC traversal of the module object */
    inquiry m_clear;          /* a clear function to call during GC clearing of the module object */
    freefunc m_free;          /* a function to call during deallocation of the module object */
  } PyModuleDef;
  - sub-interpreters allow to create several independent interpreters in the same process and perhaps even in
    the same thread, it is an almost totally separate environment for the execution of Python code. See details
    in https://docs.python.org/3/c-api/init.html#sub-interpreter-support

* typedef struct PyModuleDefBase {
    PyObject_HEAD;
    PyObject* (*m_init)(void);   /* seems like it saves initialize function for builtin modules? */
    Py_ssize_t m_index;          /* = max_module_number++ */
    PyObject *m_copy;
  } PyModuleDef_Base;

* typedef struct _is {
    struct _is *next;            /* Ex: at PyInterpreterState_New, all interpreters will be link to _PyRuntime.interpreters.head */
    struct _ts *tstate_head;     /* Ex: when new_threadstate(*interp, init) is called, new PyThreadstate will be linked to */
    int64_t id;                  /* each interpreter has its unique id, set in PyInterpreterState_New using _Pyruntime.interpreters.next_id */
    PyObject *modules;           /* Ex: init in _PyInitializeCore, it's a dict  */
    PyObject *modules_by_index;  /* a PyList, use module->m_base.m_index as index to get item */
    PyObject *sysdict;           /* this is a dictionary from sysmodule, seems like all imported module will be here */ 
    PyObject *builtins;          /* Ex: builtin module initialized in _PyInitializeCore, and this points to its dict  */ 
    PyObject *importlib;         /* Ex: at initimport, it points to a module named "_frozen_importlib" */
    int check_interval;          /* used in Python/sysmodule.c, indicate python interpreter to check asynchronous event every n (100) instructions */
    long num_threads;            /* used in Modules/_threadmodule.c, initialzied to 0 and record the current number of threads */
    size_t  pythread_stacksize   /* Support for runtime thread stacksize tuning, 0 means default size */
    PyObject *codec_search_path;     /* List, initialize in _PyCodecRegistry_Init, it's about string codec */
    PyObject *codec_search_cache;    /* same as above but it's a dict */
    PyObject *codec_error_registry;  /* same as above, a dict */
    int codecs_initialized;
    int fscodecs_initialized;
    _PyCoreConfig core_config;         /* from pymain->config, assigned by _PyCoreConfig_Copy, related to environment setup */
    _PyMainInterpreterConfig config;   /* it holds data for calling sys.path, sys.argv, ... methods under interpreter */
    int dlopenflags;
    PyObject *builtins_copy;     /* Ex: a backup of builtins, in _PyImport_Init we see interp->builtins_copy = Pydict_copy(interp->builtins) */
    PyObject *import_func;       /* Ex: from initimport, interp->import_func = PyDictGetItemString(interp->builtins, "__import__") */
    _PyFrameEvalFunction eval_frame;   /* entry function to start running code */
    Py_ssize_t co_extra_user_count;
    freefunc co_extra_freefunc[MAX_CO_EXTRA_USERS];
    PyObject *before_forkers;
    PyObject *after_forkers_parent;
    PyObject *after_forkers_child;
    void (*pyexitfunc)(PyObject *);
    PyObject *pyexitmodule; 
  } PyInterpreterState;

* typedef struct _ts{
    struct _ts *prev;
    struct _ts *next;
    PyInterpreterState *interp;
    struct _frame *frame;
    int recursion depth;
    char overflowed;          /* the stack has overflowed, allow 50 more calls to handle the runtime error */
    char recursion_critical;  /* the current calls must not cause a stack overflow */
    int stackcheck_counter;
    int tracing; /* tracing keeps track of the execution depth when tracing/profiling, to prevent the actual trace code from been recorded in trace/profile */
    int use_tracing;
    ... 
  } PyThreadState;
    - in _threadmodule.c, thread_methods[] has function thread_PyThread_start_new_thread as entry function
       - struct bootstate is allocated and initialized, boot->tstate = _PyThreadState_Prealloc, in this function new_threadstate(interp, 0) is called
       - then we call PyEval_InitThreads, the first call will create and take gil, second call will return directly
       - call PyThread_start_new_thread(t_bootstrap, (void *) boot), this function calls pthread_create() and t_bootstrap is the entry function

* t_bootstrap(void *boot_raw)
    - call PyThreadState_Init(tstate), it then calls _PyGILState_NoteThreadState(tstate), not really understand what it does
    - then it calls PyEval_AcquireThread(tstate) and it calls take_gil(tstate), this function uses conditional variable and timeout for GIL
      scheduling, it may call SET_GIL_DROP_REQUEST()
    - call tstate->interp->num_thread++, and then PyObject_Call(boot->func, boot->args, boot->keyw)  

* Python's name resolution are determined after compiling and if follows local => enclosure => global (the module file) => builtins (intrisic)

* the whole python program starts at Programs/python.c and it has two entry functions, wmain(windows) and main (Unix) and main calls 
  _Py_UnixMain(argc, argv)
    - then it calls pymain_main(&pymain), this function processes cmd_line, calls _Py_InitializeCore(see below) and then pymain_run_python(pymain)
    - then it depends on our input arguments, if pymain->command (-c), call pymain_run_command; else if pymain->module (-m), call pymain_run_module
      else (without -c and -m), we call pyname_run_filename(pymain, &cf), cf is PyCompilerFlag type ------> I follow this path
    - if pymain->filename is a package and there's a __main__.py inside, then we run pymain_run_main_from_importer, otherwise we call
      pymain_run_file(fp, pymain->filename, cf). fp can be stdio (interative mode) or real filename ------> I follow this path       
    - we call PyRun_AnyFileExFlags(fp, filename_str, filename != NULL, p_cf). filename_str = "<stdin>" at interative mode
    - if we are in interative mode, we call PyRun_InterativeLoopFlags(fp, filename, flags); otherwise we call 
      PyRun_SimpleFileExFlags(fp, filename, closeit, flags). -----> I follow this path

* _Py_InitializeCore(const _PyCoreConfig *core_config)
    - call _PyRuntime_Initialize, then _PyRuntimeState_Init(&_PyRuntime), this function can only called one and _PyRuntime is a global variable,
      then we get into _PyRuntimeState_Init_impl(&_PyRuntime) and we call _PyGC_Initialize(&runtime->gc) and _PyEval_Initialize(&runtime->ceval)
    - call _PyMem_SetupAllocators(core_config->allocator), _PyHashRandomization_Init(core_config), _PyInterpreterState_Enable(&_PyRuntime),
      interp = PyInterpreterState_New(), _PyCoreConfig_Copy(&interp->core_config, core_config), tstate = PyThreadState_New(interp), 
      PyThreadState_Swap(tstate), _PyEval_FiniThreads(), _PyGILState_Init(interp, tstate), _Py_ReadyTypes(), ... (Lots of initialization)

* PyRun_SimpleFileExFlags(FILE *fp, const char *filename, int closeit, PyCompilerFlags *flags)
    - call m = PyImport_AddModule("__main__"), this function calls PyImport_AddModuleObject(nameobj), it gets PyThreadState_GET()->interp->modules
     (a dict) and pass it into _PyImport_AddModuleObject(names, object), this function find the name from the module, or create a new module object 
     , set this new object into the module dict and return.
    - set __file__ = filename, __cached__ = None, and check if its a pyc file (call run_pyc_file), or call PyRun_FileExFlags 

* '__main__' is the name of the scope in which top-level code executes. A moduleâ€™s __name__ is set equal to '__main__' when read from standard input,
   a script, or from an interactive prompt. A module can discover whether or not it is running in the main scope by checking its own __name__, which
   allows a common idiom for conditionally executing code in a module when it is run as a script or with python -m but not when it is imported
   from https://docs.python.org/3/library/__main__.html

* PyRun_FileExFlags(FILE *fp, const char *filename_str, int start, PyObject *globals, PyObject *locals, int closeit, PyCompilerFlags *flags)    
    - it has mod_ty mod = PyParser_ASTFromFileObject(fp, filename, NULL, start, 0, 0, flags, NULL, arena), AST means Abstract Syntax Tree
    - call run_mod(mod, filename, globals, locals, flags, arena)

* run_mod(mod_ty *mod, PyObject *filename, PyObject *globals, PyObject *locals, PyCompilerFlags *flags, PyArena *arena)
    - let PyCodeObject co = PyAST_CompileObject(mod, filename, flags, -1, arena)
    - then call PyEval_EvalCode((PyObjects*) co, globals, locals), this function then call PyEval_EvalCodeEx(co, globals, locals, 0 ...) then
      it turns to _PyEval_EvalCodeWithName(co, globals, locals, 0 ...)
     
* _PyEval_EvalCodeWithName(PyObject *co, PyObject *globals, PyObject *locals, PyObject * const *kwnames, PyObject * const *kwargs, 
                           Py_ssize_t kwcount, int kwstep, PyObject * const *defs, Py_ssize_t defcount, PyObject * kwdefs, 
                           PyObject *closure, PyObject *name, PyObject *qualname)
    - Get current thread state using PyThreadState_GET()
    - Create a new frame using _PyFrame_New_NoTrack(tstate, co, globals, locals)
    - Check compiler flag and if CO_VARKEYWORDS is set, create a kwdict and set f->localsplus[argcount + kwonlyargcount + CO_VARARGS?1:0] = kwdict
    - for i < MIN(co->co_argcount, argcount), set f->localplus[i]=arg[i],
    - Create a tuple with argcount - n elements if CO_VARARGS is set, set f->localsplus[argcount + kwonlyargcount] = tuple, and insert into tuple
    - for each kwnames[i] and kwargs[i], we compare it with each co->co_varnames[j], we set f->localsplus[j] = kwargs[i], or otherwise add it to kwdict
    - check 1) too many positional args, 2) add missing positional args, 3) add missing kwargs (2 and 3 use default values)
    - for i < number of co->co_cellvars, if co->co_cell2arg is valid (a cell var is also an argument), clear the local copy and write all cellvars into
      f->localplus[co->co_nlocals + i]
    - for i < PyTuple_GET_SIZE(co->cofreevars), copy reference of PyTuple_GET_ITEM(closure, i) into freevars[PyTuple_GET_SIZE(co->co_cellvars) + i]           
    - if CO_GENERATOR | CO_COROUTINE | CO_ASYNC_GENERATOR is set, initialize gen = PyCoro_New or PyAsyncGen_New or PyGen_NewWithQualName and if its a
      coroutine, we call PyObject_CallFunction(coro_wrapper, 'N', gen) and return it, otherwise we return gen
    - if not GEN/CORO/ASYNCGEN, then we call PyEval_EvalFrameEx(f, 0), and this function returns tstate->interp->eval_frame(f, throwflag) 
      _PyEval_EvalFrameDefault is called
        
* _PyEval_EvalFrameDefault(PyFrameObject *f, int throwflag)
    - this is where we execute bytecode instructions
    - call Py_EnterRecursiveCall, which checks recursion_depth of current thread below the limit and also check the stackcheck_counter, ...
      it returns NULL if not OK
    - if tstate->use_tracing is set, we may run tstate->c_tracefunc or c_profilefunc and there's a dtrace_function_entry(f) (default off)
    - Start setting co, names, consts, fastlocals, ...first_instr, next_instr, stack_pointer, f->f_executing = 1, why = WHY_NOT
    - then we enter the massive for(;;) loop:
       - check if the eval_breaker is set, this could be set by SET_GIL_GROP_REQUEST, SIGNAL_PENDING_CALLS, SIGNAL_ASYNC_EXC MACROs
           - if this is true, then we check whether we have these events and do corresponging actions
           - if _PyRuntime.ceval.pending.calls_to_do is set, we call Py_MakePendingCalls()
           - if _PyRuntime.ceval.gil_drop_request is set, we call drop_gil(tstate) => Other thread may run now ... => take_gil(tstate)
           - if tstate->async_exc != NULL, call UNSIGNAL_ASYNC_EXC() 
       - some other trace support or profiling functions
       - call NEXTOPARG() to fetch code, and then we go into switch(opcode)
       - for loop related intructions (BREAK_LOOP, CONTINUE_LOOP), we will goto fast_block_end:, and for other kind or errors/exception we goto error:
           - In error: label, we set why = WHY_EXCEPTION, call PyTraceBack_Here(f), call call_exc_trace if tstate->c_tracefunc != NULL and we
             arrive the fast_block_end label:
           - In fast_block_end label, assert(why != WHY_NOT), it should be WHY_CONTINUE, WHY_BREAK, WHY_EXCEPTION, ... and then we start checking:
              - we get PyTryBlock *b = f->f_blockstack[f->f_iblock - 1]
              - if b->type = SETUP_LOOP and why = WHY_CONTINUE, reset next_instr according to retval and break;, if not this case we set
                f->f_iblock--
              - then if b->b_type = EXCEPT_HANDLER, call UNWIND_EXCEPT_HANDLER(b), it pops all objects from stack and recover t_state->exc_info,
                then continue;
              - call UNWIND_BLOCK(b), pop all values out of current stack
              - if b->type = SETUP_LOOP and why = WHY_BREAK, set WHY_NOT and reset next_instr with b->handler, then break;
              - if why = WHY_EXCEPTION and b->b_type = SETUP_EXCEPT || b->b_type = SETUP_FINALLY
                 - call PyFrame_BlockSetup(f, EXCEPT_HANDLER, -1, STACKLEVEL()), allocate a new blockstack and set b_type = EXCEPT_HANDLER, 
                   handler = -1 and level = STACKLEVEL()
                 - push current exc_info into stack
                 - call PyErr_Fetch to get exc = tstate->curexc_type, val = tstate->curexc_value, tb = tstate->curexc_traceback
                 - call PyErr_NormalizeException(&exc, &val, &tb), it returns appropriate exception type and value
                 - if tb != NULL, call PyException_SetTraceback(val,tb), otherwise call PyException_SetTraceback(val, Py_None)
                 - update exc_info with exc, val and tb, push exc, val, tb into stack and JUMPTO(handler), and break;
              - if b->b_type == SETUP_FINALLY, JUMPTO(b->b_handler)
       - then we leave the main loop, we pop remaining stack entries, do tracing stuff, call Py_LeaveRecursiveCall, set f->f_executing = 0
         set tstate->frame = f->f_back, and return _PyCheckFunctionResult(NULL, retval, "PyEval_EvalFrameEx") 

* all python opcodes are at Include/opcode.h

* the definition of dis.dis:
   - [line number of the source code]  [the index of the bytecode for this instruction] [human-readable instruction name] [argument of the instr] [what the argument means]
   - "LOAD_NAME 4" instruction loads co->co_names[4] into stack
   - "LOAD_CONST 5" loads co->co_consts[5] into stack

* LOAD_NAME
   - if we call dis.dis('x'), then we got this LOAD_NAME instruction, in virtual machine we first call v = PyDict_GetItem(f->f_locals, name),
     if v = NULL, then v = PyDict_GetItem(f->f_globals, name), if v = NULL then v = PyDict_GetItem(f->f_builtins, name), and PUSH(v) 

* LOAD_GLOBAL
   - similar to LOAD_NAME, we first read from global then from builtins

* LOAD_FAST
   - load co->co_varnames[x] to stack

* LOAD_CLOSURE
   - push co->cellvars[x] to stack, this instruction is used the first instruction of the decorator, then we use MAKE_FUNCTION for the return

* LOAD_DEREF
   - I see this instruction when function use variable from decorator, and it load co->cellvars[x] (like LOAD_CLOSURE) but only push co->cellvars[x].ob_ref
     to the stack, so called DEREF?

* STORE_FAST
   - co->co_varname[x] = value

* STORE_NAME
   - when we call dis.dis('import x'), then we will get STORE_NAME after IMPORT_NAME
   - this instruction tries to call PyDict_SetItem(f->f_locals, name, v), if fail then it calls PyObject_SetItem(f->f_locals, name, v)

* import_name(PyFrameObject *f, PyObject *name, PyObject *from_list, PyObject *level)
   - this is the entry function of instruction IMPORT_NAME for import xx statement
   - get import_func = PyDict_GetItemId(f->builtins, &PyId___import__)
   - if import_func = PyThreadState_GET()->interp->import_func, call PyImport_ImportModuleLevelObject(name, f->globals,
     f->f_locals, from_list, level)
      - call mod = PyImport_GetModule(absname), absname has been resolved as a valid argument, this function returns item from
        interp->modules and then return PyDict_GetItemWithError(modules, name)
      - if mod != NULL && != Py_None, we may call _PyObject_CallMethodIdObjArgs(interp->importlib, &PyId__lock_unlock_module, abs_name, NULL),
        this function acutally calls _lock_unlock_module(...) 
      - otherwise we call import_find_and_load(abs_name), and this function calls _PyObject_CallMethodIdObjArgs(interp->importlib, &PyId__find_and_load,
        abs_name, interp->import_func, NULL), this function actually call _find_and_load(...)

* import_from(PyObject *v, PyObject *name)
   - call PyObject_GetAttr(v, name):
      - return tp->tp_getattro(v, name) if tp->tp_getattro, otherwise if tp->tp_getattr return tp->tp_getattr(v, name)

* from experiences, import Mod add Mod into sys.modules and main module's dict, from xxx import y also add y into main module's dict

* typedef struct {
    PyObject_HEAD;
    PyObject *func_code;        /* a code object, the __code__ attribute */
    PyObject *func_globals;     /* a dictionary (other mappings won't do) */
    PyObject *func_defaults;    /* NULL or a tuple */
    PyObject *func_kwdefaults;  /* NULL or a dict */
    PyObject *func_closure;     /* NULL or a tuple, contains the bindings for func_code->co_freevars */
    PyObject *func_doc;         /* the __doc__ attribute, can be anything */
    PyObject *func_name;        /* the __name__ attribute, a string object */
    PyObject *func_dict;        /* the __dict__ attribute, a dict or NULL */
    PyObject *func_weakreflist  /* list of weak reference */
    PyObject *func_module;      /* the __module__ attribute, can be anything */
    PyObject *func_annotation;  /* Annotations, a dict or NULL */
    PyObject *func_qualname;    /* the qualified name */
  } PyFunctionObject;
    - function objects are created by the execution of the 'def' statement
    - there're three types in funcobject.c, PyClassMethod_Type, PyFunction_Type, PyStaticMethod_Type
    - a static method does not receive an implicit first argument, this is similar to JAVA or C++
    - a class method receives the class as its first argument, not similar to JAVA or C++

* MAKE_FUNCTION
    - this instruction creates a new function object
    - this is the instruction when we call dis.dis('def f() ...'), and it calls PyFunc_NewWithQualName(codeobj, f->f_globals, qualname)
      note that at this moment the codeobj has already been prepared 
    - then we get ob = PyObject_GC_New(PyFunctionObject, &PyFunction_Type), and ob->func_code = code, ob->func_globals = f->f_globals,
      ob->func_name = code->co_name, ob->func_doc PyTuple_GetItem(code->co_consts), ob->module = PyDict_GetItem(globals, __name__),
      ob->qualname = qualname or ob->func_name 
    - this instruction will check oparg on stack and if oparg = 0x8, we set func->func_closure = POP(); oparg =0x4 we set func->func_annotation;
      oparg = 0x2 we set func->func_kwdefaults = POP(); oparg = 0x1 we set func->func_default = POP()

* CALL_FUNCTION
  - this is the instruction when we call dis.dis('f()'), in ceval.c we have res = call_function(&sp, oparg, NULL) 
     - if this function is PyCFunctionType, call _PyCFunction_FastCallKeywords(func, stack, nargs, kwnames), for builtin functions or methods,
       always check this first because these are presumed to be called most frequently
     - else if this function is PyMethodDescr_Type, generally we call _PyMethodDescr_FastCallKeywords(func, stack, nargs, kwnames), for
       method descriptor
     - else we call PyMethod_GET_FUNCTION(func) for bound method, or _PyFunction_FastCallKeywords(func, stack, nargs, kwnames) or 
       _PyObject_FastCallKeywords(func, stack, nargs, kwnames)
     - if the function we call is pure c function then we can directly process it, otherwise we will go to the virtual machine loop again 
       
* YIELD_VALUE
     - this is the instruction I can see in generator
     - set retval = POP()
     - it checks if the co->co_flags & CO_ASYNC_GENERATOR(0x0200), if yes, retval = _PyAsyncGenValueWrapperNew(retval)
     - set f->stacktop = stack_pointer, why = WHY_YIELD, and goto fast_yield

* _PyFunction_FastCallKeywords(PyObject *func, PyObject *const *stack, Py_ssize_t nargs, PyObject *kwnames)
   - we got code, globals, argdefs, kwdefs, closure, name, qualname from function object by calling PyFunction_GET_XXX
   - then depending on whether this function has keywords and free variables or not, we call function_call_fastcall(co, stack, nargs, globals) or
     _PyEval_EvalCodeWithName(co, globals, ..., closure, name, qualname)
   - at function code, we don't use current globals but use function object's globals !     

* LOAD_BUILD_CLASS
   - this is the instruction to start building class
   - it gets bc = f->builtins['__build_class__'] and push bc to stack
   - it then do MAKE_FUNCTION to make a function object of class definition and push it to stack
   - it then do LOAD_CONST, LOAD_NAME to push base classes and class name to stack
   - it then do CALL_FUNCTION and call bc (builtin___build_class__) with argument in between
      
* builtin___build_class__(PyObject *self, PyObject * const *args, Py_ssize_t nargs, PyObject *kwnames)
   - check from stack whether there's a metaclass, if no, then we get the type from first base class or use default PyType_Type
   - if meta we got is really a class, call winner = PyType_CalculateMetaclass(meta, bases), this function check if there's a
     metaclass conflict(derived class's type should be the subclass of its base class's type) and find the most derived metaclass
     and we reassign meta = winner
   - then we try to get __prepare__ atribute from meta, if it's NULL then we set ns = 0, otherwise ns = PyObject_FastCallDict(prep, pargs, 2,mkw)
   - then we call cell = PyEval_EvalCodeEx(PyFunction_GET_CODE(func), PyFunction_GET_GLOBALS(func), ns, lots of 0, PyFunction_GET_CLOSURE(func))
     the class's code object should run here and related function objects are created and saved into the local => ns
   - it then calls _PyObject_FastCallDict(meta, margs, 3, mkw), where margs = {name, bases, ns} and mkw is the keywords on stack, and then this 
     function calls meta->tp_call (type_call)

* type_call(PyTypeObject *type, PyObject *args, PyObject *kwds)
   - it calls type->tp_new(type, args, kwds), see below
   
* type_new(PyTypeObject *metatype, PyObject *args, PyObject *kwds)
   - call PyArg_ParseTuple() and get name, bases and orig_dict
   - recheck the proper meta type from bases and if found a better one, return winner->tp_new
   - call base = best_base(bases), the first one which is on the path to "solid base"
   - call dict = PyDict_Copy(orig_dict)
   - check if __slot__ is inside the dict, if no, we update may_add_dict and may_add_weak, otherwise:
      - first check if slots is allowed, base->tp_itemsize should be 0, then check the item in slots is valid
      - then basically we create a list called slots and insert all valid items inside
   - let type = metatype->tp_alloc(metatype, nslots), tp_alloc is PyType_GenericAlloc, it's changed in _PyReadyTypes, and a PyHeapTypeObject
     is allocated (et), we can also cast it into PyTypeObject (type)
   - then we start initialize each field, tp_flags, tp_as_xxx, tp_bases, tp_base, tp_dict, set __module__ in dict, set tp_doc, special cases
     handling, ...
   - then call PyType_Ready(type) 
   - call fixup_slot_dispatcher(type), this function register a callback on such as tp_as_number.nb_add if the new type has __add__ method,
     the callback function is written in MACRO, we can check such as slot_nb_add
   - call set_names(type)
   - call init_subclass(type,kwds)

* metaclass is triggered using class C(object, metaclass=x) 

* typedef struct {
    PyObject_HEAD;
    sturct _frame *gi_frame; /* this can be NULL if the generator is finished */
    char gi_running;         /* true if generator is being executed */
    PyObject *gi_code;       /* the code object backing the generator */
    PyObject *gi_weakref;    /* list of weak reference */
    PyObject *gi_name;       /* the name of the generator */
    PyObject *gi_qualname;   /* qualified name of the generator */
    _PyErr_StackItem gi_exc_state;
  } PyGenObject;

* how is the call tree when we call next(gen)
   - next is a builtin method and LOAD_NAME will load it into stack
   - we run CALL_FUNCTION and it calls call_function
   - next is a C function ans it calls builtin_next, it then calls (*gen->ob_type->iternext)(gen)
   - then it calls gen_send_ex and it calls PyEval_EvalFrameEx ans it goes _PyEval_EvalFrameDefault(f, exc)
     where f is the frameobject on the generator object, and then the bytecode instruction starts executing

* typedef struct {
    PyObject_Head;
    PyObject *start, *stop, *step; /* not NULL */
  } PySliceObject;

* BUILD_SLICE
   - this is the instruction I can see in dis.dis('a[1:3]')
   - its oparg determines whether step is there, and it calls PySlice_New(start, stop, step), and put it at top  
   - then the next instuction is BINARY_SUBSCR

* BINARY_SUBSCR
   - this instruction gets sub, and container from stack, and then calls PyObject_GetItem(container, sub) and put result at top
   - which mean the container should handler the slice object itself

* LOAD_ATTR
   - this instruction can be shown in dis.dis('a.b.c=1'), and it does as following: LOAD_CONST (1), LOAD_NAME(a), LOAD_ATTR(b),
     STORE_ATTR(c) ...
   - call GETITEM(name, oparg), where names = co->co_names, then gets owner using TOP() and call PyObject_GetAttr(owner, name)
   - first check tp->getattro, then tp->getattr

* STORE_ATTR
   - very similar to LOAD_ATTR, call GETITEM(names, oparg) and get owner using TOP() and call PyObject_SetAttr(owner, name, v) 
   - first check tp->setattro, and then tp_setattr
